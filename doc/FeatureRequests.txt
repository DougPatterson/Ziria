------------------------------------------------------------
--- Language syntax and semantics (cosmetics):
------------------------------------------------------------

I guess this is not the most difficult bit, but it is probably
the most important for adoption of WPL. Also, we want to get 
it right from the beginning, to avoid asking our test users
to rewrite code because of syntax changes. 

General goal is to make the syntax and semantics as friendly
as possible to our target audience, which is proficient with 
Matlab and C. Here is my list of suggestions, compiled during 
a few weeks of intens programming with WPL. Please share your 
thoughts and comments: 


- Make it easier and more intuitive to combine expressions 
  and computers.
  Rename return into something else (e.g. code). Add return to 
  the last expression to feel "C" like. 
  E.g. write
       x<-take1; emit execute{s := s+1; return 3}
  Here execute{} feels like an inlined C function.

- Do we need both let x = e in c and x <- return (e); c ?
  It doesn't hurt but it might be confusing for a novice user. 
 

- Currently, returns of all computers have to be bound to an 
  immutable variable? Is this necessary? Why can't we write 

    s[0:3] := take 4,

  which would map into 
    x<-take 4; return(s[0:3] := x)
  More intuitive for C/Matlab programmer, and also with one 
  memcpy fewer? 

- The following:
  let f(n: int) = n := n/2 in ...
  fails at runtime but it should fail at the compiletime, as n is inlined into a constant!

      TODO (bug) 


- Should we get rid of immutable variables entirely? 
  It is a weird concept for C/Matlab used. In terms of efficiency, 
  they get generated anyway. We could auto-infer type and
  treat them as local, but make them mutable. 
  Related: Do we need in keyword in let ... in?


- Add support for matrices
     Bozidar. Low priority. 

- Allow different data types in expressions. 
  For example, we should be able to divide complex with int. 
  Also array with int.

     Part of what we discuss about extending numeric operations to complex and vectors. 

- Add C-type expression shortcuts: a++, b--, c+=2, ...

     DV: change parsing 

- Can we make ; on the last statement optional instead of banned?

     Done.

- Display a proper warning when a reserved word is used as a variable name
     Done.

- Add enum types
- Add case/switch statement both as an expression 
  and as a computer
  
     DV: will do. 


- Can we have if then without else as a computer? 
      Done.

- Add support for strings (e.g. for printing error messages)
      Bozidar.

- Add better support for printing. E.g. support
  println "A: ", a, " B: ", b
      Bozidar.



- Can we get rid of unit type in 
    let comp (u : unit) = ...
    comp(tt);
  and write just
    let comp () = ...
    comp()

      Done.

- Add while loop and break statement.

      DV: 
      Will add while to comp and expr language
      Will fix syntax of times in comp and expr language (call it for) 
      Will introduce break in expression language + continue;


- Complain about shadowing variables
      DV: will do.

- Do we need different types of assignments? 
  Can we not just use = for both := and <- and infer 
  which one it is?
      Ignore.

- Allow array sizes to be declared with constant expressions
  e.g. allow a : arr[(5+6)*3] int. Right now this fails.
  This is useful when the array sizes are calculated from global constants.

       DV: will do.

- Get rid of dreadful parsing error:
    "untested_wpl/test.wpl" (line 8, column 7):
    unexpected "<"
    expecting letter or digit, "(", ";", "|>>>|", ">>>", ".>>>." or "in"
  This occurs for example when missing else, such as:
   let test1 (u : unit) =
     x<-take1;
     y<-take 2;
     return (
       if (n==0) {
         t := y;
	 n := 1
       } 
     )
   in
  Also in
    let x = libf(s); 
  where ";" is used instead of in.

         DV: should be fixed.

- Sharing state story, particularly in par: m1 >>> m2 

         Leave it to the programmer for now. 

  Suppose m1 is updating some global state that m2 is reading.  For
  every element m1 takes, we update the global state and emit, so m2
  can immediately see the new global state when processing the
  element.

  However, if we /vectorize/ the first component to take e.g. 4
  elements then we might end up in a situation where, when we emit an
  element out, the visible global state that m2 sees is different than
  w/o vectorization.

  So we have several options:

   (1) Do not allow shared state between two >>> nodes. At all. We
       like that.
       -- BOZIDAR: But we may want to have the following:
       -- We initialize a global variable in the init phase
       -- and then we use it by two >>> nodes. 
       -- So the global variable is not immutable in general
       -- but it is immutable from the point of view of the two nodes.
   
   (2) Do allow shared state but make sure you detect (see below
       choices for that) and do not vectorize (or pipeline
       parallelize, for the same reasons).

       To ask the programmer to declare shared state can help with
       detection:

           withSharedState(dc) (m1 >>> m2)

       but still prevents vectorization and pipelineing because the
       semantics is not specified.

  This is related a bit to StreamIt teleport messages. You can imagine
  a pipeline:

     m1 >>> m2 >>> m3 
 
  such that m3 updates a shared state, and m1 reads the shared
  state. The semantics is then not specified. We'd have to manually
  rewrite the pipeline breaking up the computations into a big repeat
  and the computers of m1; m2; m3 to effectivelly specify the intended
  semantics.



------------------------------------------------------------
--- Debugging:
------------------------------------------------------------

Easy debugging is also key to larger adoption of WPL. I feel 
that there are a few simple things we could do to make it 
simple and efficient:

- In the code generation, add computer name string to the names 
  of all variables related to that computer, to simplify the debugging.

- Can we add WPL code as C comments in the generated code? Currently 
  it seems pp cannot do that (it removes all the comments)

- Add print exp keyword for debugging, to display any variable to the screen. 

- Add detailed reports about outcomes of each step of optimization/compilation

Other than that, I don't think that programmers will have issues
finding a line of code that they want to debug and put breakpoints in
C to check what is going on, in particular because the C code
resambles very much to the imperative portion of the WPL code.
I think Mahanth shares my view, and he has done some serious 
WPL coding and debugging. 

DV: 2 more things:

- I am wondering though if we should support some kind of
  instrumentation for debugging, because of the GOTO-based
  compilation. If we put a debugger at a particular point we have no
  clue about *how* we jumped to that point and from which previous
  point.  There's no call stack (but maybe the easiest thing is to
  maintain that "virtual" stack actually manually as a data structure.

- We need to have comments printed out nicely in the C file. I will
  ask if Geoff can do that.


------------------------------------------------------------
--- Language features:
------------------------------------------------------------

We've discussed finalizers and concluded that they would be 
useful but that they were not the top priority. Given that we
are rethinking the language, it might be good to add this now. 
It is cleary the only fundamental feature Mahanth and I found 
missing while implementing WiFi (and at least conceptually LTE). 

To remind you, the goal of finalizers would be to allow each 
block in a chain to nicely output remaining data when its component
is about to yield. 


- Static inits that execute only once ever

  DV: I perceive this as a hint to the compiler that 
  says: *Partially evaluate me* and if you can't then just fail.

  DV: interesting but probably lower priority 


------------------------------------------------------------
--- Array operations:
------------------------------------------------------------

I think we may want to add array operations to WPL for two
reasons. The first is that they are extensively used in Matlab, which
is a language of choice for most of the users we target, and would
help adoption of the language.  The second reason is that it would
very likely allow much easier "SIMD"ification.

Here are a few examples: 
- Dot product: c = a * b' = a * transpose(b) 
      	       (a,b are vectors of the same size)
  Pseudo-code: c = 0;
  	       for i=1:length(a) 
	         c = c + a(i)*b(i)

- Element-wise operations: c = a .* b, d = a + b, 
     e = a ./ b, f = a .^ b (a,b are vectors of the same size)
  Pseudo-code: c(i) = a(i) * b(i), ...

- Array functions: c = f(a)
  Pseudo-code: c(i) = f(a(i)) for all i=1:length(a)

- Special functions: c = sum(a), d = cumsum(a), f = diff(a), ...
 
(for more details please see: 
 http://www.mathworks.co.uk/help/matlab/ref/arithmeticoperators.html)

Note that Matlab supports matrices, but we don't need to (someone
may implement it in future, if there is interest). 


Introduction of such "high-level" operations on arrays might allow us
easier and more seamless SIMD-ification. Consider the following two 
examples: 

1) If x, y and z are vectors/arrays, then we can map 
   z = x - y into vsubw(z,x,y), which is our proxy for SSE 
   array subtraction instruction. This mapping would be trivial. 
   At the moment, we either have to use an external function 
   (which is not very difficult but certainly more than writing x-y)
   or figure out that a for loop is doing such a thing
   (which is possible but tedious). 
   However, Matlab users are very used to say x-y, so this would 
   benefit both the compiler and a user. 

2) RemoveDC is a WiFi block that does the following: 
      sum_dc := sum_dc + (sum(x) / 32);				(*) 
   where x is arr[4] complex and sum_dec is a scalar. 
   This is a relatively common DSP/wireless code for a simple filter. 
   An efficient SIMD implementation is:
         shift_rightw(x,5,tmp);
         haddw(tmp, sumx);
         addw( sum_dc, sumx, sum_dc );
   where:
   - haddw computes sum of all 4 components in a vector128 type, 
     and duplicate the final value to all elements in the returned vector
   - addw sums two arr[4] complex vectors (_mm_add_epi16). 
   
   It is relatively easy to map (*) to this SIMD implementation. 
   However, it would be much more difficult to do so without array operations. 
   Clearly, the key question is how much very specific operations we want
   to map efficiently to SIMD. I feel that many very common DSP/wireless blocks
   (filters, correlators, etc) could be easilty optimized from array optimizations
   which seems preferable to me then writing lots of incomprehensible external 
   functions. 






------------------------------------------------------------
--- Memory management:
------------------------------------------------------------

This is not really my area of expertize, but I feel that currently 
we might be overdoing with memcpy. For correctness each array
is (almost) always passed by value. Is there a well-understood,
systematic way to deal with variable passing and array copying? 
Can we go through the compiler's code, understand what is going on,
and find a good trade-off between passing by reference and value. 

Also, we currently don't do any out-of-bound array read/write checks?
Shall we add some? Or leave it to C (and related tools)? Does it make
sense to add some guarantees? What are your thoughts on this issue?

- Make sure passing arrays by reference is consistent




------------------------------------------------------------
--- Performance
------------------------------------------------------------

Lots of functions are not inlined now, because of the structure of our code.
Hence we pay a penalty when compared to Sora. But we also compile quicker. 
We should make this configurable. For example, consider sseExternals.c file.
We can define all functions as inlined in sseExternals.h. 
Then if we compile a debug version, we create an empty sseExternals.c file
with one line: #include "sseExternals.h". 
If we compile a release version, we include sseExternals.h directly into test.c.

This applies to library functions, drivers and possibly others. 





------------------------------------------------------------
--- Sora supports
------------------------------------------------------------

- Allow someone else to control the main loop (e.g. MAC). 
  Sora MAC design assumes PHY returns quickly to the main loop. 
  We could do the same, return from the main loop often and resume when needed. 
  
- Add support for multiple Blink loops in the same code (e.g. TX and RX)

- Compile Blink code as a library that can be statically linked into another codebase



------------------------------------------------------------
--- Polymorphic arrays
------------------------------------------------------------
This works fine now. However, it is not allowed to 
generate locally or return a polymorphic array from a function with
polymorphic arguments. Instead, once should allocate all the necessary 
arrays externally and pass them to the function (by reference). 

*NOTE*: Dimitrios doesn't like this, so we will revisit


------------------------------------------------------------
-- Code restructuring
------------------------------------------------------------

Make a global lib directory for shared blink library functions 
(such as sum(arr)) and with signatures for all external functions.

Think of a structure in which a user can add new external functions
without touching Blink repository



------------------------------------------------------------
-- Auto casting
------------------------------------------------------------
Casting is currently a major issue as everything needs to 
be specified manually. There are several things we can automatize
easily. For example, we can cast automatically int16 -> int32 in
an operation of sort
   (int32)a + (int16) b
Also, we could cast (int16) into (complex16) by setting im=0.
Further, we can add support for mixed operations. 
For example:
   (complex16)a / (int16)b = complex16{re=a.re/b; im=a.im/b}

